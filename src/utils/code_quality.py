"""
ä»£ç è´¨é‡æ£€æŸ¥å’Œæ”¹è¿›å·¥å…·
æä¾›ç±»å‹æ³¨è§£ã€æ–‡æ¡£å­—ç¬¦ä¸²ã€ä»£ç è§„èŒƒæ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½
"""

import ast
import inspect
import re
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union, Set
from dataclasses import dataclass
from pathlib import Path
import importlib.util
from datetime import datetime


@dataclass
class QualityIssue:
    """ä»£ç è´¨é‡é—®é¢˜æ•°æ®ç±»"""
    file_path: str
    line_number: int
    issue_type: str
    severity: str  # 'error', 'warning', 'info'
    message: str
    suggestion: Optional[str] = None


@dataclass
class QualityMetrics:
    """ä»£ç è´¨é‡æŒ‡æ ‡æ•°æ®ç±»"""
    total_lines: int
    documented_functions: int
    total_functions: int
    type_annotated_functions: int
    complexity_score: float
    maintainability_index: float
    test_coverage: float
    issues_count: Dict[str, int]


class TypeAnnotationChecker:
    """ç±»å‹æ³¨è§£æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.issues: List[QualityIssue] = []
    
    def check_file(self, file_path: str) -> List[QualityIssue]:
        """æ£€æŸ¥æ–‡ä»¶çš„ç±»å‹æ³¨è§£"""
        self.issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            self._check_ast_node(tree, file_path)
            
        except Exception as e:
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=1,
                issue_type="parse_error",
                severity="error",
                message=f"æ— æ³•è§£ææ–‡ä»¶: {str(e)}"
            ))
        
        return self.issues
    
    def _check_ast_node(self, node: ast.AST, file_path: str):
        """é€’å½’æ£€æŸ¥ASTèŠ‚ç‚¹"""
        for child in ast.walk(node):
            if isinstance(child, ast.FunctionDef):
                self._check_function_annotations(child, file_path)
            elif isinstance(child, ast.ClassDef):
                self._check_class_annotations(child, file_path)
    
    def _check_function_annotations(self, node: ast.FunctionDef, file_path: str):
        """æ£€æŸ¥å‡½æ•°ç±»å‹æ³¨è§£"""
        # æ£€æŸ¥å‚æ•°æ³¨è§£
        for arg in node.args.args:
            if not arg.annotation and arg.arg != 'self':
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=node.lineno,
                    issue_type="missing_type_annotation",
                    severity="warning",
                    message=f"å‡½æ•° '{node.name}' çš„å‚æ•° '{arg.arg}' ç¼ºå°‘ç±»å‹æ³¨è§£",
                    suggestion=f"ä¸ºå‚æ•° '{arg.arg}' æ·»åŠ ç±»å‹æ³¨è§£ï¼Œä¾‹å¦‚: {arg.arg}: str"
                ))
        
        # æ£€æŸ¥è¿”å›å€¼æ³¨è§£
        if not node.returns and not node.name.startswith('_'):
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type="missing_return_annotation",
                severity="warning",
                message=f"å‡½æ•° '{node.name}' ç¼ºå°‘è¿”å›å€¼ç±»å‹æ³¨è§£",
                suggestion=f"ä¸ºå‡½æ•° '{node.name}' æ·»åŠ è¿”å›å€¼æ³¨è§£ï¼Œä¾‹å¦‚: -> None æˆ– -> str"
            ))
    
    def _check_class_annotations(self, node: ast.ClassDef, file_path: str):
        """æ£€æŸ¥ç±»å±æ€§æ³¨è§£"""
        for child in node.body:
            if isinstance(child, ast.AnnAssign) and not child.annotation:
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=child.lineno,
                    issue_type="missing_attribute_annotation",
                    severity="info",
                    message=f"ç±» '{node.name}' çš„å±æ€§ç¼ºå°‘ç±»å‹æ³¨è§£"
                ))


class DocstringChecker:
    """æ–‡æ¡£å­—ç¬¦ä¸²æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.issues: List[QualityIssue] = []
    
    def check_file(self, file_path: str) -> List[QualityIssue]:
        """æ£€æŸ¥æ–‡ä»¶çš„æ–‡æ¡£å­—ç¬¦ä¸²"""
        self.issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            self._check_ast_node(tree, file_path)
            
        except Exception as e:
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=1,
                issue_type="parse_error",
                severity="error",
                message=f"æ— æ³•è§£ææ–‡ä»¶: {str(e)}"
            ))
        
        return self.issues
    
    def _check_ast_node(self, node: ast.AST, file_path: str):
        """é€’å½’æ£€æŸ¥ASTèŠ‚ç‚¹"""
        for child in ast.walk(node):
            if isinstance(child, ast.FunctionDef):
                self._check_function_docstring(child, file_path)
            elif isinstance(child, ast.ClassDef):
                self._check_class_docstring(child, file_path)
    
    def _check_function_docstring(self, node: ast.FunctionDef, file_path: str):
        """æ£€æŸ¥å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²"""
        docstring = ast.get_docstring(node)
        
        if not docstring and not node.name.startswith('_'):
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type="missing_docstring",
                severity="warning",
                message=f"å‡½æ•° '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                suggestion=f"ä¸ºå‡½æ•° '{node.name}' æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°å…¶åŠŸèƒ½ã€å‚æ•°å’Œè¿”å›å€¼"
            ))
        elif docstring:
            self._validate_docstring_format(docstring, node.name, file_path, node.lineno)
    
    def _check_class_docstring(self, node: ast.ClassDef, file_path: str):
        """æ£€æŸ¥ç±»æ–‡æ¡£å­—ç¬¦ä¸²"""
        docstring = ast.get_docstring(node)
        
        if not docstring:
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type="missing_class_docstring",
                severity="warning",
                message=f"ç±» '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                suggestion=f"ä¸ºç±» '{node.name}' æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°å…¶ç”¨é€”å’Œä¸»è¦åŠŸèƒ½"
            ))
        elif docstring:
            self._validate_docstring_format(docstring, node.name, file_path, node.lineno)
    
    def _validate_docstring_format(self, docstring: str, name: str, file_path: str, line_number: int):
        """éªŒè¯æ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼"""
        lines = docstring.strip().split('\n')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç®€çŸ­æè¿°
        if not lines[0].strip():
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=line_number,
                issue_type="docstring_format",
                severity="info",
                message=f"{name} çš„æ–‡æ¡£å­—ç¬¦ä¸²åº”ä»¥ç®€çŸ­æè¿°å¼€å§‹"
            ))
        
        # æ£€æŸ¥æ˜¯å¦è¿‡çŸ­
        if len(docstring.strip()) < 10:
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=line_number,
                issue_type="docstring_too_short",
                severity="info",
                message=f"{name} çš„æ–‡æ¡£å­—ç¬¦ä¸²è¿‡äºç®€çŸ­ï¼Œåº”æä¾›æ›´è¯¦ç»†çš„æè¿°"
            ))


class CodeStyleChecker:
    """ä»£ç é£æ ¼æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.issues: List[QualityIssue] = []
    
    def check_file(self, file_path: str) -> List[QualityIssue]:
        """æ£€æŸ¥æ–‡ä»¶çš„ä»£ç é£æ ¼"""
        self.issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            self._check_line_length(lines, file_path)
            self._check_naming_conventions(file_path)
            self._check_imports(lines, file_path)
            self._check_whitespace(lines, file_path)
            
        except Exception as e:
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=1,
                issue_type="read_error",
                severity="error",
                message=f"æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}"
            ))
        
        return self.issues
    
    def _check_line_length(self, lines: List[str], file_path: str):
        """æ£€æŸ¥è¡Œé•¿åº¦"""
        max_length = 88  # PEP 8 æ¨èçš„æœ€å¤§è¡Œé•¿åº¦
        
        for i, line in enumerate(lines, 1):
            if len(line.rstrip()) > max_length:
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=i,
                    issue_type="line_too_long",
                    severity="warning",
                    message=f"ç¬¬ {i} è¡Œè¿‡é•¿ ({len(line.rstrip())} > {max_length} å­—ç¬¦)",
                    suggestion="è€ƒè™‘å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œ"
                ))
    
    def _check_naming_conventions(self, file_path: str):
        """æ£€æŸ¥å‘½åçº¦å®š"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    self._check_function_naming(node, file_path)
                elif isinstance(node, ast.ClassDef):
                    self._check_class_naming(node, file_path)
                elif isinstance(node, ast.Name):
                    self._check_variable_naming(node, file_path)
                    
        except Exception:
            pass  # å·²åœ¨å…¶ä»–åœ°æ–¹å¤„ç†è§£æé”™è¯¯
    
    def _check_function_naming(self, node: ast.FunctionDef, file_path: str):
        """æ£€æŸ¥å‡½æ•°å‘½å"""
        if not re.match(r'^[a-z_][a-z0-9_]*$', node.name) and not node.name.startswith('__'):
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type="naming_convention",
                severity="info",
                message=f"å‡½æ•°å '{node.name}' ä¸ç¬¦åˆ snake_case å‘½åçº¦å®š",
                suggestion="ä½¿ç”¨ snake_case å‘½åçº¦å®šï¼Œä¾‹å¦‚: my_function"
            ))
    
    def _check_class_naming(self, node: ast.ClassDef, file_path: str):
        """æ£€æŸ¥ç±»å‘½å"""
        if not re.match(r'^[A-Z][a-zA-Z0-9]*$', node.name):
            self.issues.append(QualityIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type="naming_convention",
                severity="info",
                message=f"ç±»å '{node.name}' ä¸ç¬¦åˆ PascalCase å‘½åçº¦å®š",
                suggestion="ä½¿ç”¨ PascalCase å‘½åçº¦å®šï¼Œä¾‹å¦‚: MyClass"
            ))
    
    def _check_variable_naming(self, node: ast.Name, file_path: str):
        """æ£€æŸ¥å˜é‡å‘½å"""
        if isinstance(node.ctx, ast.Store):
            if node.id.isupper() and len(node.id) > 1:
                # å¸¸é‡åº”è¯¥å…¨å¤§å†™
                if '_' not in node.id:
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        issue_type="naming_convention",
                        severity="info",
                        message=f"å¸¸é‡ '{node.id}' å»ºè®®ä½¿ç”¨ä¸‹åˆ’çº¿åˆ†éš”",
                        suggestion="ä½¿ç”¨ UPPER_CASE å‘½åçº¦å®šï¼Œä¾‹å¦‚: MY_CONSTANT"
                    ))
    
    def _check_imports(self, lines: List[str], file_path: str):
        """æ£€æŸ¥å¯¼å…¥è¯­å¥"""
        import_lines = []
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            if stripped.startswith('import ') or stripped.startswith('from '):
                import_lines.append((i, stripped))
        
        # æ£€æŸ¥å¯¼å…¥é¡ºåº
        if len(import_lines) > 1:
            prev_type = self._get_import_type(import_lines[0][1])
            for i, (line_num, import_line) in enumerate(import_lines[1:], 1):
                current_type = self._get_import_type(import_line)
                if current_type < prev_type:
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=line_num,
                        issue_type="import_order",
                        severity="info",
                        message="å¯¼å…¥è¯­å¥é¡ºåºä¸æ­£ç¡®",
                        suggestion="æŒ‰ç…§æ ‡å‡†åº“ã€ç¬¬ä¸‰æ–¹åº“ã€æœ¬åœ°æ¨¡å—çš„é¡ºåºæ’åˆ—å¯¼å…¥"
                    ))
                prev_type = current_type
    
    def _get_import_type(self, import_line: str) -> int:
        """è·å–å¯¼å…¥ç±»å‹ï¼ˆç”¨äºæ’åºï¼‰"""
        if import_line.startswith('from __future__'):
            return 0
        elif any(lib in import_line for lib in ['os', 'sys', 'json', 'datetime', 'typing']):
            return 1  # æ ‡å‡†åº“
        elif any(lib in import_line for lib in ['streamlit', 'pandas', 'numpy', 'plotly']):
            return 2  # ç¬¬ä¸‰æ–¹åº“
        else:
            return 3  # æœ¬åœ°æ¨¡å—
    
    def _check_whitespace(self, lines: List[str], file_path: str):
        """æ£€æŸ¥ç©ºç™½å­—ç¬¦"""
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥è¡Œå°¾ç©ºç™½
            if line.rstrip() != line.rstrip('\n'):
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=i,
                    issue_type="trailing_whitespace",
                    severity="info",
                    message=f"ç¬¬ {i} è¡Œæœ‰è¡Œå°¾ç©ºç™½å­—ç¬¦"
                ))
            
            # æ£€æŸ¥åˆ¶è¡¨ç¬¦
            if '\t' in line:
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=i,
                    issue_type="tab_character",
                    severity="warning",
                    message=f"ç¬¬ {i} è¡Œä½¿ç”¨äº†åˆ¶è¡¨ç¬¦ï¼Œå»ºè®®ä½¿ç”¨ç©ºæ ¼"
                ))


class ComplexityAnalyzer:
    """å¤æ‚åº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.complexity_scores: Dict[str, int] = {}
    
    def analyze_file(self, file_path: str) -> Dict[str, int]:
        """åˆ†ææ–‡ä»¶å¤æ‚åº¦"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    complexity = self._calculate_cyclomatic_complexity(node)
                    self.complexity_scores[f"{file_path}::{node.name}"] = complexity
            
        except Exception:
            pass
        
        return self.complexity_scores
    
    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, (ast.And, ast.Or)):
                complexity += 1
            elif isinstance(child, ast.comprehension):
                complexity += 1
        
        return complexity


class QualityReporter:
    """ä»£ç è´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.type_checker = TypeAnnotationChecker()
        self.doc_checker = DocstringChecker()
        self.style_checker = CodeStyleChecker()
        self.complexity_analyzer = ComplexityAnalyzer()
    
    def analyze_project(self, project_path: str) -> QualityMetrics:
        """åˆ†ææ•´ä¸ªé¡¹ç›®çš„ä»£ç è´¨é‡"""
        all_issues = []
        total_lines = 0
        total_functions = 0
        documented_functions = 0
        type_annotated_functions = 0
        complexity_scores = []
        
        # è·å–æ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(Path(project_path).rglob("*.py"))
        
        for file_path in python_files:
            file_path_str = str(file_path)
            
            # æ£€æŸ¥ç±»å‹æ³¨è§£
            type_issues = self.type_checker.check_file(file_path_str)
            all_issues.extend(type_issues)
            
            # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
            doc_issues = self.doc_checker.check_file(file_path_str)
            all_issues.extend(doc_issues)
            
            # æ£€æŸ¥ä»£ç é£æ ¼
            style_issues = self.style_checker.check_file(file_path_str)
            all_issues.extend(style_issues)
            
            # åˆ†æå¤æ‚åº¦
            complexity_scores_file = self.complexity_analyzer.analyze_file(file_path_str)
            complexity_scores.extend(complexity_scores_file.values())
            
            # ç»Ÿè®¡æŒ‡æ ‡
            try:
                with open(file_path_str, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines += len(lines)
                
                tree = ast.parse(open(file_path_str, 'r', encoding='utf-8').read())
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        total_functions += 1
                        if ast.get_docstring(node):
                            documented_functions += 1
                        if node.returns or any(arg.annotation for arg in node.args.args):
                            type_annotated_functions += 1
                            
            except Exception:
                continue
        
        # è®¡ç®—æŒ‡æ ‡
        issues_count = {}
        for issue in all_issues:
            issues_count[issue.issue_type] = issues_count.get(issue.issue_type, 0) + 1
        
        avg_complexity = sum(complexity_scores) / len(complexity_scores) if complexity_scores else 0
        maintainability_index = max(0, 171 - 5.2 * np.log(total_lines) - 0.23 * avg_complexity - 16.2 * np.log(total_lines / total_functions if total_functions > 0 else 1))
        
        return QualityMetrics(
            total_lines=total_lines,
            documented_functions=documented_functions,
            total_functions=total_functions,
            type_annotated_functions=type_annotated_functions,
            complexity_score=avg_complexity,
            maintainability_index=maintainability_index,
            test_coverage=0.0,  # éœ€è¦é¢å¤–å·¥å…·è®¡ç®—
            issues_count=issues_count
        )
    
    def generate_report(self, project_path: str) -> str:
        """ç”Ÿæˆä»£ç è´¨é‡æŠ¥å‘Š"""
        metrics = self.analyze_project(project_path)
        
        report = f"""
# ä»£ç è´¨é‡æŠ¥å‘Š

## ğŸ“Š æ€»ä½“æŒ‡æ ‡

- **æ€»è¡Œæ•°**: {metrics.total_lines:,}
- **å‡½æ•°æ€»æ•°**: {metrics.total_functions}
- **æ–‡æ¡£è¦†ç›–ç‡**: {(metrics.documented_functions / metrics.total_functions * 100) if metrics.total_functions > 0 else 0:.1f}%
- **ç±»å‹æ³¨è§£è¦†ç›–ç‡**: {(metrics.type_annotated_functions / metrics.total_functions * 100) if metrics.total_functions > 0 else 0:.1f}%
- **å¹³å‡å¤æ‚åº¦**: {metrics.complexity_score:.1f}
- **å¯ç»´æŠ¤æ€§æŒ‡æ•°**: {metrics.maintainability_index:.1f}

## ğŸ” é—®é¢˜ç»Ÿè®¡

"""
        
        for issue_type, count in metrics.issues_count.items():
            report += f"- **{issue_type}**: {count} ä¸ªé—®é¢˜\n"
        
        report += f"""

## ğŸ“ˆ è´¨é‡è¯„çº§

"""
        
        # è®¡ç®—æ€»ä½“è¯„çº§
        doc_score = (metrics.documented_functions / metrics.total_functions * 100) if metrics.total_functions > 0 else 0
        type_score = (metrics.type_annotated_functions / metrics.total_functions * 100) if metrics.total_functions > 0 else 0
        complexity_score = max(0, 100 - metrics.complexity_score * 10)
        maintainability_score = min(100, metrics.maintainability_index)
        
        overall_score = (doc_score + type_score + complexity_score + maintainability_score) / 4
        
        if overall_score >= 90:
            grade = "A+ (ä¼˜ç§€)"
        elif overall_score >= 80:
            grade = "A (è‰¯å¥½)"
        elif overall_score >= 70:
            grade = "B (ä¸€èˆ¬)"
        elif overall_score >= 60:
            grade = "C (éœ€è¦æ”¹è¿›)"
        else:
            grade = "D (æ€¥éœ€æ”¹è¿›)"
        
        report += f"**æ€»ä½“è¯„çº§**: {grade} ({overall_score:.1f}/100)\n\n"
        
        return report


# å…¨å±€è´¨é‡æ£€æŸ¥å™¨å®ä¾‹
quality_reporter = QualityReporter()


def check_code_quality(project_path: str = ".") -> str:
    """æ£€æŸ¥ä»£ç è´¨é‡å¹¶ç”ŸæˆæŠ¥å‘Š"""
    return quality_reporter.generate_report(project_path)


def get_quality_metrics(project_path: str = ".") -> QualityMetrics:
    """è·å–ä»£ç è´¨é‡æŒ‡æ ‡"""
    return quality_reporter.analyze_project(project_path)